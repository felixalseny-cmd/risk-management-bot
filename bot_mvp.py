# bot_mvp_phase3.py ‚Äî PRO Risk Calculator MVP Phase 3 (Complete)
import os
import sys
import logging
import asyncio
import time
import functools
import json
import re
import html
import gc
import io
import csv
import math
from datetime import datetime, timedelta
from typing import Dict, List, Any, Tuple, Optional, Union
from enum import Enum
from decimal import Decimal, ROUND_HALF_UP
from collections import defaultdict
from dataclasses import dataclass, asdict
import base64

# --- Load .env ---
from dotenv import load_dotenv
load_dotenv()

# --- Configuration ---
TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
if not TOKEN:
    raise ValueError("TELEGRAM_BOT_TOKEN not found!")

PORT = int(os.getenv("PORT", 10000))
WEBHOOK_URL = os.getenv("WEBHOOK_URL", "").rstrip("/")
WEBHOOK_PATH = f"/webhook/{TOKEN}"

# API Keys (–∏—Å–ø–æ–ª—å–∑—É–µ–º –∏–∑ .env –∏–ª–∏ –¥–µ—Ñ–æ–ª—Ç—ã)
BINANCE_API_KEY = os.getenv("BINANCE_API_KEY")
FMP_API_KEY = os.getenv("FMP_API_KEY")

# --- Logging ---
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)
logger = logging.getLogger("risk_calculator_pro")

# ==================== ADVANCED DATA STRUCTURES ====================
@dataclass
class AssetMetrics:
    """–†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –∞–∫—Ç–∏–≤–∞"""
    symbol: str
    current_price: float
    mean_return: float
    volatility: float
    annual_volatility: float
    historical_var_95: float
    historical_var_99: float
    parametric_var_95: float
    conditional_var_95: float
    max_drawdown: float
    sharpe_ratio: float
    sortino_ratio: float
    skewness: float
    kurtosis: float
    monte_carlo_var_95: float
    monte_carlo_prob_loss: float
    atr_14: float  # Average True Range
    rsi_14: float  # Relative Strength Index
    last_updated: str

@dataclass
class PortfolioMetrics:
    """–ú–µ—Ç—Ä–∏–∫–∏ –ø–æ—Ä—Ç—Ñ–µ–ª—è"""
    total_value: float
    num_assets: int
    portfolio_var_95: float
    portfolio_cvar_95: float
    portfolio_volatility: float
    portfolio_sharpe: float
    portfolio_sortino: float
    portfolio_beta: float
    diversification_score: float  # 0-100
    concentration_risk: float  # Herfindahl-Hirschman Index
    correlation_risk: float
    worst_case_loss: float
    expected_shortfall: float
    stress_test_results: List[Dict]

# ==================== ADVANCED GRAPH GENERATOR ====================
class AdvancedGraphGenerator:
    """–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã—Ö –≥—Ä–∞—Ñ–∏–∫–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ä–∏—Å–∫–æ–≤"""
    
    def __init__(self):
        self.figures_created = 0
        self.memory_limit = 50  # –ú–∞–∫—Å–∏–º—É–º 50 –≥—Ä–∞—Ñ–∏–∫–æ–≤ –≤ –ø–∞–º—è—Ç–∏
        
    def cleanup_old_figures(self):
        """–û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –≥—Ä–∞—Ñ–∏–∫–æ–≤ –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏"""
        if self.figures_created > self.memory_limit:
            gc.collect()
            self.figures_created = 0
            logger.info("–û—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏ –≥—Ä–∞—Ñ–∏–∫–æ–≤")
    
    @monitor_performance
    def generate_monte_carlo_chart(self, initial_price: float, sample_paths: List[List[float]], 
                                 final_prices: List[float], symbol: str) -> io.BytesIO:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≥—Ä–∞—Ñ–∏–∫–∞ Monte Carlo —Å–∏–º—É–ª—è—Ü–∏–∏"""
        try:
            import matplotlib.pyplot as plt
            import matplotlib
            matplotlib.use('Agg')  # Non-interactive backend
            import numpy as np
            
            self.cleanup_old_figures()
            
            plt.figure(figsize=(12, 8), dpi=100)
            
            # Plot sample paths
            days = len(sample_paths[0]) if sample_paths else 30
            x = np.arange(days)
            
            for i, path in enumerate(sample_paths[:50]):  # Limit to 50 paths for clarity
                alpha = 0.1 if i > 10 else 0.3  # Highlight first 10 paths
                plt.plot(x, path, 'b-', alpha=alpha, linewidth=0.5)
            
            # Calculate and plot confidence intervals
            if sample_paths:
                paths_array = np.array(sample_paths)
                mean_path = np.mean(paths_array, axis=0)
                std_path = np.std(paths_array, axis=0)
                
                plt.plot(x, mean_path, 'r-', linewidth=3, label='–°—Ä–µ–¥–Ω—è—è —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏—è')
                plt.fill_between(x, mean_path - std_path, mean_path + std_path, 
                               alpha=0.2, color='red', label='¬±1œÉ')
                plt.fill_between(x, mean_path - 2*std_path, mean_path + 2*std_path, 
                               alpha=0.1, color='red', label='¬±2œÉ')
            
            # Plot initial price line
            plt.axhline(y=initial_price, color='g', linestyle='--', linewidth=2, 
                       label=f'–ù–∞—á–∞–ª—å–Ω–∞—è —Ü–µ–Ω–∞: ${initial_price:.2f}')
            
            # Formatting
            plt.title(f'Monte Carlo –°–∏–º—É–ª—è—Ü–∏—è: {symbol}\n30-–¥–Ω–µ–≤–Ω—ã–π –ø—Ä–æ–≥–Ω–æ–∑', fontsize=16, fontweight='bold')
            plt.xlabel('–î–Ω–∏', fontsize=12)
            plt.ylabel('–¶–µ–Ω–∞ ($)', fontsize=12)
            plt.grid(True, alpha=0.3)
            plt.legend(loc='upper left')
            
            # Add statistics box
            if final_prices:
                stats_text = (
                    f'–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ñ–∏–Ω–∞–ª—å–Ω—ã—Ö —Ü–µ–Ω:\n'
                    f'–°—Ä–µ–¥–Ω—è—è: ${np.mean(final_prices):.2f}\n'
                    f'–ú–µ–¥–∏–∞–Ω–∞: ${np.median(final_prices):.2f}\n'
                    f'95% VaR: ${initial_price * (1 - np.percentile(final_prices, 5)/100):.2f}\n'
                    f'–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —É–±—ã—Ç–∫–∞: {100 * sum(1 for p in final_prices if p < initial_price)/len(final_prices):.1f}%'
                )
                plt.text(0.02, 0.98, stats_text, transform=plt.gca().transAxes,
                        fontsize=9, verticalalignment='top',
                        bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))
            
            # Save to bytes buffer
            buffer = io.BytesIO()
            plt.tight_layout()
            plt.savefig(buffer, format='png', dpi=150, bbox_inches='tight')
            buffer.seek(0)
            
            plt.close()
            self.figures_created += 1
            
            return buffer
            
        except Exception as e:
            logger.error(f"Error generating Monte Carlo chart: {e}")
            raise
    
    @monitor_performance
    def generate_distribution_chart(self, returns: List[float], symbol: str) -> io.BytesIO:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≥—Ä–∞—Ñ–∏–∫–∞ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–µ–π"""
        try:
            import matplotlib.pyplot as plt
            import matplotlib
            matplotlib.use('Agg')
            import numpy as np
            from scipy.stats import norm
            
            self.cleanup_old_figures()
            
            plt.figure(figsize=(12, 8), dpi=100)
            
            returns_array = np.array(returns)
            mean, std = np.mean(returns_array), np.std(returns_array)
            
            # Histogram of returns
            plt.hist(returns_array, bins=50, density=True, alpha=0.6, color='blue', 
                   label='–ò—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏')
            
            # Normal distribution fit
            x = np.linspace(min(returns_array), max(returns_array), 100)
            p = norm.pdf(x, mean, std)
            plt.plot(x, p, 'r-', linewidth=2, label=f'–ù–æ—Ä–º–∞–ª—å–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ (Œº={mean:.4f}, œÉ={std:.4f})')
            
            # VaR lines
            var_95 = np.percentile(returns_array, 5)
            var_99 = np.percentile(returns_array, 1)
            
            plt.axvline(x=var_95, color='orange', linestyle='--', linewidth=2, label=f'95% VaR = {var_95:.2%}')
            plt.axvline(x=var_99, color='red', linestyle='--', linewidth=2, label=f'99% VaR = {var_99:.2%}')
            
            # CVaR area
            cvar_returns = returns_array[returns_array <= var_95]
            if len(cvar_returns) > 0:
                plt.axvspan(min(cvar_returns), var_95, alpha=0.2, color='red', label='Conditional VaR –æ–±–ª–∞—Å—Ç—å')
            
            # Formatting
            plt.title(f'–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–µ–π: {symbol}\n–î–Ω–µ–≤–Ω—ã–µ –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏', fontsize=16, fontweight='bold')
            plt.xlabel('–î–æ—Ö–æ–¥–Ω–æ—Å—Ç—å', fontsize=12)
            plt.ylabel('–ü–ª–æ—Ç–Ω–æ—Å—Ç—å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏', fontsize=12)
            plt.grid(True, alpha=0.3)
            plt.legend(loc='upper right')
            
            # Add statistics
            skew = float(np.cov(returns_array)[0, 0]) if len(returns_array) > 1 else 0
            kurt = float(np.cov(returns_array, rowvar=False)[0, 0]) if len(returns_array) > 1 else 0
            
            stats_text = (
                f'–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è:\n'
                f'–°—Ä–µ–¥–Ω–µ–µ: {mean:.4f}\n'
                f'–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ: {std:.4f}\n'
                f'–ê—Å–∏–º–º–µ—Ç—Ä–∏—è: {skew:.2f}\n'
                f'–≠–∫—Å—Ü–µ—Å—Å: {kurt:.2f}\n'
                f'–¢–µ—Å—Ç –Ω–∞ –Ω–æ—Ä–º–∞–ª—å–Ω–æ—Å—Ç—å: {"–û—Ç–∫–ª–æ–Ω–µ–Ω–æ" if abs(skew) > 0.5 or abs(kurt-3) > 1 else "–ù–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–æ"}'
            )
            plt.text(0.02, 0.98, stats_text, transform=plt.gca().transAxes,
                    fontsize=9, verticalalignment='top',
                    bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))
            
            buffer = io.BytesIO()
            plt.tight_layout()
            plt.savefig(buffer, format='png', dpi=150, bbox_inches='tight')
            buffer.seek(0)
            
            plt.close()
            self.figures_created += 1
            
            return buffer
            
        except Exception as e:
            logger.error(f"Error generating distribution chart: {e}")
            raise
    
    @monitor_performance
    def generate_correlation_matrix(self, assets: List[str], returns_matrix: np.ndarray) -> io.BytesIO:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –º–∞—Ç—Ä–∏—Ü—ã –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π –∞–∫—Ç–∏–≤–æ–≤"""
        try:
            import matplotlib.pyplot as plt
            import matplotlib
            matplotlib.use('Agg')
            import numpy as np
            import seaborn as sns
            
            self.cleanup_old_figures()
            
            plt.figure(figsize=(12, 10), dpi=100)
            
            # Calculate correlation matrix
            corr_matrix = np.corrcoef(returns_matrix.T)
            
            # Create heatmap
            mask = np.triu(np.ones_like(corr_matrix, dtype=bool))
            sns.heatmap(corr_matrix, mask=mask, annot=True, fmt='.2f', cmap='RdYlGn_r',
                       center=0, square=True, linewidths=.5, cbar_kws={"shrink": .8})
            
            plt.title('–ú–∞—Ç—Ä–∏—Ü–∞ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π –∞–∫—Ç–∏–≤–æ–≤ –ø–æ—Ä—Ç—Ñ–µ–ª—è', fontsize=16, fontweight='bold')
            plt.xticks(ticks=np.arange(len(assets)) + 0.5, labels=assets, rotation=45, ha='right')
            plt.yticks(ticks=np.arange(len(assets)) + 0.5, labels=assets, rotation=0)
            
            # Add portfolio diversification score
            if len(assets) > 1:
                avg_correlation = np.mean(np.abs(corr_matrix[np.triu_indices_from(corr_matrix, k=1)]))
                diversification = 1 - avg_correlation
                
                plt.text(0.02, -0.1, 
                        f'–°—Ä–µ–¥–Ω—è—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è: {avg_correlation:.2f} | –û—Ü–µ–Ω–∫–∞ –¥–∏–≤–µ—Ä—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏: {diversification:.2f}/1.0',
                        transform=plt.gca().transAxes, fontsize=10,
                        bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.8))
            
            buffer = io.BytesIO()
            plt.tight_layout()
            plt.savefig(buffer, format='png', dpi=150, bbox_inches='tight')
            buffer.seek(0)
            
            plt.close()
            self.figures_created += 1
            
            return buffer
            
        except Exception as e:
            logger.error(f"Error generating correlation matrix: {e}")
            raise
    
    @monitor_performance
    def generate_stress_test_chart(self, stress_results: List[Dict]) -> io.BytesIO:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≥—Ä–∞—Ñ–∏–∫–∞ —Å—Ç—Ä–µ—Å—Å-—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
        try:
            import matplotlib.pyplot as plt
            import matplotlib
            matplotlib.use('Agg')
            import numpy as np
            
            self.cleanup_old_figures()
            
            plt.figure(figsize=(14, 8), dpi=100)
            
            scenarios = [r['scenario'] for r in stress_results]
            losses = [r['loss_percent'] for r in stress_results]
            colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FFEAA7']
            
            bars = plt.barh(scenarios, losses, color=colors[:len(scenarios)])
            plt.xlabel('–ü–æ—Ç–µ—Ä–∏ (%)', fontsize=12)
            plt.title('–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å—Ç—Ä–µ—Å—Å-—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –ø–æ—Ä—Ç—Ñ–µ–ª—è', fontsize=16, fontweight='bold')
            
            # Add value labels on bars
            for bar, loss in zip(bars, losses):
                plt.text(bar.get_width() + 0.5, bar.get_y() + bar.get_height()/2,
                        f'{loss:.1f}%', va='center', fontweight='bold')
            
            # Add recovery time annotations
            for i, result in enumerate(stress_results):
                plt.text(-2, i, f"–í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ: ~{result['recovery_months']} –º–µ—Å.",
                        va='center', fontsize=9, color='gray')
            
            plt.grid(True, alpha=0.3, axis='x')
            plt.xlim(-5, max(losses) * 1.2)
            
            buffer = io.BytesIO()
            plt.tight_layout()
            plt.savefig(buffer, format='png', dpi=150, bbox_inches='tight')
            buffer.seek(0)
            
            plt.close()
            self.figures_created += 1
            
            return buffer
            
        except Exception as e:
            logger.error(f"Error generating stress test chart: {e}")
            raise
    
    @monitor_performance
    def generate_risk_radar_chart(self, metrics: Dict[str, float]) -> io.BytesIO:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–∞–¥–∞—Ä-–¥–∏–∞–≥—Ä–∞–º–º—ã —Ä–∏—Å–∫–æ–≤"""
        try:
            import matplotlib.pyplot as plt
            import matplotlib
            matplotlib.use('Agg')
            import numpy as np
            
            self.cleanup_old_figures()
            
            categories = ['–í–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å', '–†–∏—Å–∫ —Å–Ω–∏–∂–µ–Ω–∏—è', '–ö–æ–Ω—Ü–µ–Ω—Ç—Ä–∞—Ü–∏—è', 
                         '–ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è', '–õ–∏–∫–≤–∏–¥–Ω–æ—Å—Ç—å', '–†—ã–Ω–æ—á–Ω—ã–π —Ä–∏—Å–∫']
            
            values = [
                metrics.get('volatility_score', 50),
                metrics.get('drawdown_risk', 50),
                metrics.get('concentration_risk', 50),
                metrics.get('correlation_risk', 50),
                metrics.get('liquidity_risk', 50),
                metrics.get('market_risk', 50)
            ]
            
            N = len(categories)
            angles = [n / float(N) * 2 * np.pi for n in range(N)]
            values += values[:1]
            angles += angles[:1]
            
            fig, ax = plt.subplots(figsize=(10, 10), subplot_kw=dict(projection='polar'), dpi=100)
            
            ax.plot(angles, values, 'o-', linewidth=2)
            ax.fill(angles, values, alpha=0.25)
            
            ax.set_xticks(angles[:-1])
            ax.set_xticklabels(categories, fontsize=12)
            ax.set_ylim(0, 100)
            
            # Add risk level annotations
            risk_level = np.mean(values)
            if risk_level < 30:
                risk_text = "–ù–ò–ó–ö–ò–ô –†–ò–°–ö"
                color = 'green'
            elif risk_level < 60:
                risk_text = "–£–ú–ï–†–ï–ù–ù–´–ô –†–ò–°–ö"
                color = 'orange'
            else:
                risk_text = "–í–´–°–û–ö–ò–ô –†–ò–°–ö"
                color = 'red'
            
            plt.title(f'–ü—Ä–æ—Ñ–∏–ª—å —Ä–∏—Å–∫–∞ –ø–æ—Ä—Ç—Ñ–µ–ª—è\n{risk_text}', fontsize=16, fontweight='bold', color=color)
            
            # Add value labels
            for angle, value, category in zip(angles[:-1], values[:-1], categories):
                ax.text(angle, value + 5, f'{value:.0f}', ha='center', va='center', fontsize=10)
            
            buffer = io.BytesIO()
            plt.tight_layout()
            plt.savefig(buffer, format='png', dpi=150, bbox_inches='tight')
            buffer.seek(0)
            
            plt.close()
            self.figures_created += 1
            
            return buffer
            
        except Exception as e:
            logger.error(f"Error generating radar chart: {e}")
            raise

# ==================== ADVANCED REPORT GENERATOR ====================
class ReportGenerator:
    """–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã—Ö –æ—Ç—á–µ—Ç–æ–≤ –≤ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–∞—Ö"""
    
    @staticmethod
    def generate_text_report(metrics: AssetMetrics) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –æ—Ç—á–µ—Ç–∞"""
        report = [
            "=" * 60,
            f"–ê–ù–ê–õ–ò–¢–ò–ß–ï–°–ö–ò–ô –û–¢–ß–ï–¢: {metrics.symbol}",
            f"–î–∞—Ç–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {datetime.now().strftime('%Y-%m-%d %H:%M')}",
            "=" * 60,
            "",
            "üìä –û–°–ù–û–í–ù–´–ï –ú–ï–¢–†–ò–ö–ò:",
            f"  ‚Ä¢ –¢–µ–∫—É—â–∞—è —Ü–µ–Ω–∞: ${metrics.current_price:.2f}",
            f"  ‚Ä¢ –î–Ω–µ–≤–Ω–∞—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å: {metrics.volatility:.2f}%",
            f"  ‚Ä¢ –ì–æ–¥–æ–≤–∞—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å: {metrics.annual_volatility:.2f}%",
            f"  ‚Ä¢ –°—Ä–µ–¥–Ω—è—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å: {metrics.mean_return:.4f}",
            "",
            "‚ö†Ô∏è –ú–ï–¢–†–ò–ö–ò –†–ò–°–ö–ê:",
            f"  ‚Ä¢ VaR 95% (1 –¥–µ–Ω—å): {metrics.historical_var_95:.2f}%",
            f"  ‚Ä¢ VaR 99% (1 –¥–µ–Ω—å): {metrics.historical_var_99:.2f}%",
            f"  ‚Ä¢ Conditional VaR 95%: {metrics.conditional_var_95:.2f}%",
            f"  ‚Ä¢ –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ —Å–Ω–∏–∂–µ–Ω–∏–µ: {metrics.max_drawdown:.2f}%",
            "",
            "üìà –ü–û–ö–ê–ó–ê–¢–ï–õ–ò –≠–§–§–ï–ö–¢–ò–í–ù–û–°–¢–ò:",
            f"  ‚Ä¢ –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –®–∞—Ä–ø–∞: {metrics.sharpe_ratio:.2f}",
            f"  ‚Ä¢ –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –°–æ—Ä—Ç–∏–Ω–æ: {metrics.sortino_ratio:.2f}",
            f"  ‚Ä¢ –ê—Å–∏–º–º–µ—Ç—Ä–∏—è: {metrics.skewness:.2f}",
            f"  ‚Ä¢ –≠–∫—Å—Ü–µ—Å—Å: {metrics.kurtosis:.2f}",
            "",
            "üé≤ MONTE CARLO –ê–ù–ê–õ–ò–ó:",
            f"  ‚Ä¢ VaR 95% (30 –¥–Ω–µ–π): {metrics.monte_carlo_var_95:.2f}%",
            f"  ‚Ä¢ –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —É–±—ã—Ç–∫–∞: {metrics.monte_carlo_prob_loss:.1f}%",
            "",
            "üìä –¢–ï–•–ù–ò–ß–ï–°–ö–ò–ï –ò–ù–î–ò–ö–ê–¢–û–†–´:",
            f"  ‚Ä¢ ATR (14): {metrics.atr_14:.2f}",
            f"  ‚Ä¢ RSI (14): {metrics.rsi_14:.1f}",
            f"    { '‚ü≥ –ü–µ—Ä–µ–ø—Ä–æ–¥–∞–Ω–Ω–æ—Å—Ç—å' if metrics.rsi_14 < 30 else '‚ü≥ –ü–µ—Ä–µ–∫—É–ø–ª–µ–Ω–Ω–æ—Å—Ç—å' if metrics.rsi_14 > 70 else '‚ü≥ –ù–µ–π—Ç—Ä–∞–ª—å–Ω–æ'}",
            "",
            "üí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:",
        ]
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –º–µ—Ç—Ä–∏–∫
        recommendations = []
        
        if metrics.historical_var_95 > 5:
            recommendations.append("  ‚Ä¢ –í—ã—Å–æ–∫–∏–π —Ä–∏—Å–∫ - —Ä–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ —É–º–µ–Ω—å—à–µ–Ω–∏–µ –ø–æ–∑–∏—Ü–∏–∏")
        if metrics.sharpe_ratio < 1:
            recommendations.append("  ‚Ä¢ –ù–∏–∑–∫–∞—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å –Ω–∞ –µ–¥–∏–Ω–∏—Ü—É —Ä–∏—Å–∫–∞")
        if metrics.rsi_14 > 70:
            recommendations.append("  ‚Ä¢ –í–æ–∑–º–æ–∂–Ω–∞—è –ø–µ—Ä–µ–∫—É–ø–ª–µ–Ω–Ω–æ—Å—Ç—å")
        elif metrics.rsi_14 < 30:
            recommendations.append("  ‚Ä¢ –í–æ–∑–º–æ–∂–Ω–∞—è –ø–µ—Ä–µ–ø—Ä–æ–¥–∞–Ω–Ω–æ—Å—Ç—å")
        if not recommendations:
            recommendations.append("  ‚Ä¢ –ê–∫—Ç–∏–≤ –≤—ã–≥–ª—è–¥–∏—Ç —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ")
        
        report.extend(recommendations)
        report.extend([
            "",
            "=" * 60,
            "–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ: PRO Risk Calculator MVP v3.0",
            "=" * 60
        ])
        
        return "\n".join(report)
    
    @staticmethod
    def generate_portfolio_report(portfolio_metrics: PortfolioMetrics, 
                                assets: List[AssetMetrics]) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞ –ø–æ –ø–æ—Ä—Ç—Ñ–µ–ª—é"""
        report = [
            "=" * 60,
            "–û–¢–ß–ï–¢ –ü–û –£–ü–†–ê–í–õ–ï–ù–ò–Æ –†–ò–°–ö–ê–ú–ò –ü–û–†–¢–§–ï–õ–Ø",
            f"–î–∞—Ç–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {datetime.now().strftime('%Y-%m-%d %H:%M')}",
            "=" * 60,
            "",
            f"üí∞ –û–ë–©–ê–Ø –°–¢–û–ò–ú–û–°–¢–¨: ${portfolio_metrics.total_value:,.2f}",
            f"üìà –ê–ö–¢–ò–í–û–í: {portfolio_metrics.num_assets}",
            "",
            "üìä –°–í–û–î–ù–´–ï –ú–ï–¢–†–ò–ö–ò –†–ò–°–ö–ê:",
            f"  ‚Ä¢ VaR 95% –ø–æ—Ä—Ç—Ñ–µ–ª—è: {portfolio_metrics.portfolio_var_95:.1f}%",
            f"  ‚Ä¢ CVaR 95% –ø–æ—Ä—Ç—Ñ–µ–ª—è: {portfolio_metrics.portfolio_cvar_95:.1f}%",
            f"  ‚Ä¢ –í–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å –ø–æ—Ä—Ç—Ñ–µ–ª—è: {portfolio_metrics.portfolio_volatility:.1f}%",
            f"  ‚Ä¢ –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –®–∞—Ä–ø–∞: {portfolio_metrics.portfolio_sharpe:.2f}",
            f"  ‚Ä¢ –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –°–æ—Ä—Ç–∏–Ω–æ: {portfolio_metrics.portfolio_sortino:.2f}",
            f"  ‚Ä¢ –ë–µ—Ç–∞ –ø–æ—Ä—Ç—Ñ–µ–ª—è: {portfolio_metrics.portfolio_beta:.2f}",
            "",
            "üéØ –û–¶–ï–ù–ö–ê –î–ò–í–ï–†–°–ò–§–ò–ö–ê–¶–ò–ò:",
            f"  ‚Ä¢ –û—Ü–µ–Ω–∫–∞ –¥–∏–≤–µ—Ä—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏: {portfolio_metrics.diversification_score:.0f}/100",
            f"  ‚Ä¢ –†–∏—Å–∫ –∫–æ–Ω—Ü–µ–Ω—Ç—Ä–∞—Ü–∏–∏: {portfolio_metrics.concentration_risk:.2f}",
            f"  ‚Ä¢ –†–∏—Å–∫ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏: {portfolio_metrics.correlation_risk:.2f}",
            "",
            "‚ö†Ô∏è –≠–ö–°–¢–†–ï–ú–ê–õ–¨–ù–´–ï –°–¶–ï–ù–ê–†–ò–ò:",
            f"  ‚Ä¢ –•—É–¥—à–∏–µ –ø–æ—Ç–µ—Ä–∏ (99%): {portfolio_metrics.worst_case_loss:.1f}%",
            f"  ‚Ä¢ –û–∂–∏–¥–∞–µ–º—ã–µ –ø–æ—Ç–µ—Ä–∏ –≤ –∫—Ä–∏–∑–∏—Å: {portfolio_metrics.expected_shortfall:.1f}%",
            "",
            "üìâ –†–ï–ó–£–õ–¨–¢–ê–¢–´ –°–¢–†–ï–°–°-–¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø:",
        ]
        
        for stress in portfolio_metrics.stress_test_results[:3]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º 3 —Å—Ü–µ–Ω–∞—Ä–∏—è
            report.append(f"  ‚Ä¢ {stress['scenario']}: -{stress['loss_percent']:.1f}% (–≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ: {stress['recovery_months']} –º–µ—Å.)")
        
        report.extend([
            "",
            "üìä –î–ï–¢–ê–õ–ò–ó–ê–¶–ò–Ø –ü–û –ê–ö–¢–ò–í–ê–ú:",
        ])
        
        for asset in assets:
            report.extend([
                f"  ‚îÄ {asset.symbol}:",
                f"    ‚Ä¢ –¶–µ–Ω–∞: ${asset.current_price:.2f}",
                f"    ‚Ä¢ VaR 95%: {asset.historical_var_95:.1f}%",
                f"    ‚Ä¢ –í–∫–ª–∞–¥ –≤ —Ä–∏—Å–∫: {asset.volatility/portfolio_metrics.portfolio_volatility*100:.1f}%",
            ])
        
        report.extend([
            "",
            "üí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –ü–û –£–ü–†–ê–í–õ–ï–ù–ò–Æ –†–ò–°–ö–ê–ú–ò:",
        ])
        
        recommendations = []
        if portfolio_metrics.diversification_score < 60:
            recommendations.append("  ‚Ä¢ –ù–∏–∑–∫–∞—è –¥–∏–≤–µ—Ä—Å–∏—Ñ–∏–∫–∞—Ü–∏—è - –¥–æ–±–∞–≤—å—Ç–µ –∞–∫—Ç–∏–≤—ã –∏–∑ —Ä–∞–∑–Ω—ã—Ö –∫–ª–∞—Å—Å–æ–≤")
        if portfolio_metrics.portfolio_var_95 > 8:
            recommendations.append("  ‚Ä¢ –í—ã—Å–æ–∫–∏–π —Å–æ–≤–æ–∫—É–ø–Ω—ã–π —Ä–∏—Å–∫ - —É–º–µ–Ω—å—à–∏—Ç–µ –ø–æ–∑–∏—Ü–∏–∏ –≤ –≤–æ–ª–∞—Ç–∏–ª—å–Ω—ã—Ö –∞–∫—Ç–∏–≤–∞—Ö")
        if portfolio_metrics.concentration_risk > 0.3:
            recommendations.append("  ‚Ä¢ –í—ã—Å–æ–∫–∏–π —Ä–∏—Å–∫ –∫–æ–Ω—Ü–µ–Ω—Ç—Ä–∞—Ü–∏–∏ - —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–∏—Ç–µ –∫–∞–ø–∏—Ç–∞–ª –±–æ–ª–µ–µ —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ")
        if not recommendations:
            recommendations.append("  ‚Ä¢ –ü–æ—Ä—Ç—Ñ–µ–ª—å —Ö–æ—Ä–æ—à–æ —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω –ø–æ —Ä–∏—Å–∫–∞–º")
        
        report.extend(recommendations)
        report.extend([
            "",
            "=" * 60,
            "–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ: PRO Risk Calculator MVP v3.0",
            "=" * 60
        ])
        
        return "\n".join(report)
    
    @staticmethod
    def generate_csv_report(metrics: AssetMetrics) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è CSV –æ—Ç—á–µ—Ç–∞"""
        import csv
        import io
        
        output = io.StringIO()
        writer = csv.writer(output)
        
        # –ó–∞–≥–æ–ª–æ–≤–æ–∫
        writer.writerow(["PRO Risk Calculator - –ê–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–π –æ—Ç—á–µ—Ç"])
        writer.writerow([f"–ê–∫—Ç–∏–≤: {metrics.symbol}"])
        writer.writerow([f"–î–∞—Ç–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {datetime.now().strftime('%Y-%m-%d %H:%M')}"])
        writer.writerow([])
        
        # –û—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        writer.writerow(["–û–°–ù–û–í–ù–´–ï –ú–ï–¢–†–ò–ö–ò"])
        writer.writerow(["–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å", "–ó–Ω–∞—á–µ–Ω–∏–µ", "–ï–¥–∏–Ω–∏—Ü–∞ –∏–∑–º–µ—Ä–µ–Ω–∏—è"])
        writer.writerow(["–¢–µ–∫—É—â–∞—è —Ü–µ–Ω–∞", f"{metrics.current_price:.2f}", "USD"])
        writer.writerow(["–°—Ä–µ–¥–Ω—è—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å", f"{metrics.mean_return:.6f}", "–¥–æ–ª–∏"])
        writer.writerow(["–î–Ω–µ–≤–Ω–∞—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å", f"{metrics.volatility:.4f}", "–¥–æ–ª–∏"])
        writer.writerow(["–ì–æ–¥–æ–≤–∞—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å", f"{metrics.annual_volatility:.4f}", "–¥–æ–ª–∏"])
        writer.writerow([])
        
        # –ú–µ—Ç—Ä–∏–∫–∏ —Ä–∏—Å–∫–∞
        writer.writerow(["–ú–ï–¢–†–ò–ö–ò –†–ò–°–ö–ê"])
        writer.writerow(["–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å", "–ó–Ω–∞—á–µ–Ω–∏–µ", "–ï–¥–∏–Ω–∏—Ü–∞ –∏–∑–º–µ—Ä–µ–Ω–∏—è"])
        writer.writerow(["VaR 95% (1 –¥–µ–Ω—å)", f"{metrics.historical_var_95:.4f}", "%"])
        writer.writerow(["VaR 99% (1 –¥–µ–Ω—å)", f"{metrics.historical_var_99:.4f}", "%"])
        writer.writerow(["Conditional VaR 95%", f"{metrics.conditional_var_95:.4f}", "%"])
        writer.writerow(["–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ —Å–Ω–∏–∂–µ–Ω–∏–µ", f"{metrics.max_drawdown:.4f}", "%"])
        writer.writerow([])
        
        # –ü–æ–∫–∞–∑–∞—Ç–µ–ª–∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
        writer.writerow(["–ü–û–ö–ê–ó–ê–¢–ï–õ–ò –≠–§–§–ï–ö–¢–ò–í–ù–û–°–¢–ò"])
        writer.writerow(["–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å", "–ó–Ω–∞—á–µ–Ω–∏–µ"])
        writer.writerow(["–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –®–∞—Ä–ø–∞", f"{metrics.sharpe_ratio:.4f}"])
        writer.writerow(["–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –°–æ—Ä—Ç–∏–Ω–æ", f"{metrics.sortino_ratio:.4f}"])
        writer.writerow(["–ê—Å–∏–º–º–µ—Ç—Ä–∏—è", f"{metrics.skewness:.4f}"])
        writer.writerow(["–≠–∫—Å—Ü–µ—Å—Å", f"{metrics.kurtosis:.4f}"])
        writer.writerow([])
        
        return output.getvalue()
    
    @staticmethod
    def generate_json_report(metrics: AssetMetrics) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è JSON –æ—Ç—á–µ—Ç–∞"""
        report = {
            "metadata": {
                "report_type": "asset_risk_analysis",
                "generated_at": datetime.now().isoformat(),
                "version": "3.0",
                "asset": metrics.symbol
            },
            "price_data": {
                "current_price": metrics.current_price,
                "currency": "USD"
            },
            "risk_metrics": {
                "daily_volatility": metrics.volatility,
                "annual_volatility": metrics.annual_volatility,
                "var_95": metrics.historical_var_95,
                "var_99": metrics.historical_var_99,
                "cvar_95": metrics.conditional_var_95,
                "max_drawdown": metrics.max_drawdown,
                "monte_carlo_var_95": metrics.monte_carlo_var_95
            },
            "performance_metrics": {
                "mean_return": metrics.mean_return,
                "sharpe_ratio": metrics.sharpe_ratio,
                "sortino_ratio": metrics.sortino_ratio,
                "skewness": metrics.skewness,
                "kurtosis": metrics.kurtosis
            },
            "technical_indicators": {
                "atr_14": metrics.atr_14,
                "rsi_14": metrics.rsi_14,
                "rsi_interpretation": "oversold" if metrics.rsi_14 < 30 else "overbought" if metrics.rsi_14 > 70 else "neutral"
            },
            "recommendations": {
                "risk_level": "high" if metrics.historical_var_95 > 5 else "medium" if metrics.historical_var_95 > 2 else "low",
                "action": "reduce" if metrics.historical_var_95 > 5 else "hold" if metrics.sharpe_ratio > 1 else "review"
            }
        }
        
        return json.dumps(report, indent=2, ensure_ascii=False)

# ==================== ENHANCED ANALYTICS ENGINE ====================
class EnhancedAnalyticsEngine:
    """–†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–π –¥–≤–∏–∂–æ–∫ —Å —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–º–∏ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–∞–º–∏"""
    
    @staticmethod
    @monitor_performance
    def calculate_technical_indicators(prices: List[float]) -> Dict[str, float]:
        """–†–∞—Å—á–µ—Ç —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤"""
        import numpy as np
        
        if len(prices) < 15:
            return {"atr_14": 0.0, "rsi_14": 50.0}
        
        prices_array = np.array(prices)
        
        # Calculate RSI (Relative Strength Index)
        def calculate_rsi(prices, period=14):
            deltas = np.diff(prices)
            seed = deltas[:period]
            up = seed[seed >= 0].sum() / period
            down = -seed[seed < 0].sum() / period
            rs = up / down if down != 0 else 0
            rsi = 100 - 100 / (1 + rs)
            
            for i in range(period, len(deltas)):
                delta = deltas[i]
                if delta > 0:
                    up_val = delta
                    down_val = 0
                else:
                    up_val = 0
                    down_val = -delta
                
                up = (up * (period - 1) + up_val) / period
                down = (down * (period - 1) + down_val) / period
                rs = up / down if down != 0 else 0
                rsi = np.append(rsi, 100 - 100 / (1 + rs))
            
            return rsi[-1] if len(rsi) > 0 else 50
        
        # Calculate ATR (Average True Range)
        def calculate_atr(prices, period=14):
            if len(prices) < period + 1:
                return 0.0
            
            high = prices  # Simplified - using same prices for high/low
            low = prices
            close = prices
            
            tr = np.maximum(
                high[1:] - low[1:],
                np.abs(high[1:] - close[:-1]),
                np.abs(low[1:] - close[:-1])
            )
            
            atr = np.zeros_like(prices)
            atr[period] = np.mean(tr[:period])
            
            for i in range(period + 1, len(prices)):
                atr[i] = (atr[i-1] * (period - 1) + tr[i-1]) / period
            
            return atr[-1] if len(atr) > period else 0.0
        
        rsi_14 = calculate_rsi(prices_array)
        atr_14 = calculate_atr(prices_array)
        
        return {
            "atr_14": float(atr_14),
            "rsi_14": float(rsi_14),
            "price_trend": "up" if prices_array[-1] > prices_array[0] else "down"
        }
    
    @staticmethod
    @monitor_performance
    def calculate_portfolio_diversification(weights: List[float], 
                                          correlation_matrix: np.ndarray) -> Dict[str, float]:
        """–†–∞—Å—á–µ—Ç –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π –¥–∏–≤–µ—Ä—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –ø–æ—Ä—Ç—Ñ–µ–ª—è"""
        import numpy as np
        
        weights_array = np.array(weights)
        
        # Herfindahl-Hirschman Index (HHI) for concentration
        hhi = np.sum(weights_array ** 2)
        
        # Effective number of assets (diversification metric)
        effective_n = 1 / hhi if hhi > 0 else len(weights)
        
        # Average pairwise correlation
        if len(weights) > 1:
            # Get upper triangle of correlation matrix (excluding diagonal)
            upper_tri = correlation_matrix[np.triu_indices_from(correlation_matrix, k=1)]
            avg_correlation = np.mean(np.abs(upper_tri)) if len(upper_tri) > 0 else 0
        else:
            avg_correlation = 0
        
        # Diversification score (0-100)
        diversification_score = min(100, effective_n / len(weights) * 100) if len(weights) > 0 else 0
        diversification_score *= (1 - avg_correlation)  # Penalize for high correlations
        
        return {
            "concentration_risk": float(hhi),
            "effective_assets": float(effective_n),
            "avg_correlation": float(avg_correlation),
            "diversification_score": float(diversification_score)
        }
    
    @staticmethod
    @monitor_performance
    def calculate_scenario_analysis(portfolio_value: float, 
                                  asset_allocations: Dict[str, float],
                                  scenarios: Dict[str, Dict[str, float]]) -> List[Dict[str, Any]]:
        """–†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤"""
        results = []
        
        for scenario_name, impacts in scenarios.items():
            total_impact = 0
            for asset_class, allocation in asset_allocations.items():
                impact = impacts.get(asset_class, 0)
                total_impact += impact * allocation
            
            stressed_value = portfolio_value * (1 + total_impact)
            
            # Calculate additional metrics
            recovery_time = EnhancedAnalyticsEngine.estimate_recovery_time(total_impact)
            margin_call_risk = EnhancedAnalyticsEngine.calculate_margin_call_risk(total_impact)
            
            results.append({
                "scenario": scenario_name,
                "stressed_value": round(stressed_value, 2),
                "loss_percent": round(abs(total_impact) * 100, 1),
                "drawdown": round(abs(total_impact) * 100, 1),
                "recovery_months": recovery_time,
                "margin_call_risk": margin_call_risk,
                "severity": "high" if abs(total_impact) > 0.4 else "medium" if abs(total_impact) > 0.2 else "low"
            })
        
        return results
    
    @staticmethod
    def estimate_recovery_time(loss_percent: float) -> int:
        """–û—Ü–µ–Ω–∫–∞ –≤—Ä–µ–º–µ–Ω–∏ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –ø–æ—Å–ª–µ –ø–æ—Ç–µ—Ä—å"""
        loss_abs = abs(loss_percent)
        
        if loss_abs <= 0.1:  # 10%
            return 3
        elif loss_abs <= 0.2:  # 20%
            return 6
        elif loss_abs <= 0.3:  # 30%
            return 12
        elif loss_abs <= 0.4:  # 40%
            return 18
        else:  # > 40%
            return 24
    
    @staticmethod
    def calculate_margin_call_risk(loss_percent: float) -> str:
        """–†–∞—Å—á–µ—Ç —Ä–∏—Å–∫–∞ –º–∞—Ä–∂–∏–Ω-–∫–æ–ª–ª–∞"""
        loss_abs = abs(loss_percent)
        
        if loss_abs > 0.5:
            return "–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π"
        elif loss_abs > 0.3:
            return "–í—ã—Å–æ–∫–∏–π"
        elif loss_abs > 0.15:
            return "–£–º–µ—Ä–µ–Ω–Ω—ã–π"
        else:
            return "–ù–∏–∑–∫–∏–π"

# ==================== ENHANCED TELEGRAM BOT ====================
# –†–∞—Å—à–∏—Ä—è–µ–º –±–æ—Ç–∞ –∏–∑ Phase 2 —Å –Ω–æ–≤—ã–º–∏ —Ñ—É–Ω–∫—Ü–∏—è–º–∏

class EnhancedTelegramBot(TelegramRiskBot):
    """–†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π Telegram –±–æ—Ç —Å –≥—Ä–∞—Ñ–∏–∫–∞–º–∏ –∏ –æ—Ç—á–µ—Ç–∞–º–∏"""
    
    def __init__(self, token: str):
        super().__init__(token)
        self.graph_generator = AdvancedGraphGenerator()
        self.report_generator = ReportGenerator()
        self.analytics_engine = EnhancedAnalyticsEngine()
        
        # –ò—Å—Ç–æ—Ä–∏—è –∑–∞–ø—Ä–æ—Å–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
        self.user_history = defaultdict(list)
    
    async def advanced_analysis(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """–†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å –≥—Ä–∞—Ñ–∏–∫–∞–º–∏"""
        query = update.callback_query
        await query.answer()
        
        user_id = query.from_user.id
        
        text = (
            "üìà *–†–ê–°–®–ò–†–ï–ù–ù–´–ô –ê–ù–ê–õ–ò–ó*\n\n"
            "–í—ã–±–µ—Ä–∏—Ç–µ —Ç–∏–ø –∞–Ω–∞–ª–∏–∑–∞:\n\n"
            "‚Ä¢ üìä *–ü–æ–ª–Ω—ã–π –æ—Ç—á–µ—Ç* - –¥–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å –≥—Ä–∞—Ñ–∏–∫–∞–º–∏\n"
            "‚Ä¢ üé≤ *Monte Carlo* - —Å–∏–º—É–ª—è—Ü–∏—è —Ü–µ–Ω–æ–≤—ã—Ö —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏–π\n"
            "‚Ä¢ üìâ *–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–µ–π* - –∞–Ω–∞–ª–∏–∑ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏\n"
            "‚Ä¢ ‚ö†Ô∏è *–°—Ç—Ä–µ—Å—Å-—Ç–µ—Å—Ç* - –∞–Ω–∞–ª–∏–∑ —É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç–∏ –ø–æ—Ä—Ç—Ñ–µ–ª—è\n"
            "‚Ä¢ üéØ *–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã* - ATR, RSI, —Ç—Ä–µ–Ω–¥—ã\n"
            "‚Ä¢ üì§ *–≠–∫—Å–ø–æ—Ä—Ç –æ—Ç—á–µ—Ç–∞* - –æ—Ç—á–µ—Ç—ã –≤ TXT/CSV/JSON"
        )
        
        keyboard = [
            [InlineKeyboardButton("üìä –ü–æ–ª–Ω—ã–π –æ—Ç—á–µ—Ç", callback_data="full_report")],
            [InlineKeyboardButton("üé≤ Monte Carlo", callback_data="monte_carlo_chart")],
            [InlineKeyboardButton("üìâ –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ", callback_data="distribution_chart")],
            [
                InlineKeyboardButton("‚ö° –ë—ã—Å—Ç—Ä—ã–π –∞–Ω–∞–ª–∏–∑", callback_data="quick_analysis"),
                InlineKeyboardButton("üì§ –≠–∫—Å–ø–æ—Ä—Ç", callback_data="export_menu")
            ],
            [InlineKeyboardButton("üè† –ì–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é", callback_data="main_menu")]
        ]
        
        await query.edit_message_text(
            text=text,
            parse_mode='Markdown',
            reply_markup=InlineKeyboardMarkup(keyboard)
        )
    
    async def generate_full_report(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–æ–ª–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞ —Å –≥—Ä–∞—Ñ–∏–∫–∞–º–∏"""
        query = update.callback_query
        await query.answer()
        
        user_id = query.from_user.id
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏—Å—Ç–æ—Ä–∏—é –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        if user_id not in self.user_history or not self.user_history[user_id]:
            await query.edit_message_text(
                text="‚ùå –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ –∞–∫—Ç–∏–≤ –∏–ª–∏ –ø–æ—Ä—Ç—Ñ–µ–ª—å.",
                parse_mode='Markdown'
            )
            return
        
        # –ü–æ–ª—É—á–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π –∞–Ω–∞–ª–∏–∑
        last_analysis = self.user_history[user_id][-1]
        
        await query.edit_message_text(
            text="üîÑ –ì–µ–Ω–µ—Ä–∏—Ä—É—é –ø–æ–ª–Ω—ã–π –æ—Ç—á–µ—Ç... –≠—Ç–æ –∑–∞–π–º–µ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–µ–∫—É–Ω–¥.",
            parse_mode='Markdown'
        )
        
        try:
            # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –æ—Ç—á–µ—Ç–∞
            text_report = self.report_generator.generate_text_report(last_analysis['metrics'])
            
            # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≥—Ä–∞—Ñ–∏–∫–æ–≤
            if 'monte_carlo_data' in last_analysis:
                mc_chart = self.graph_generator.generate_monte_carlo_chart(
                    last_analysis['metrics'].current_price,
                    last_analysis['monte_carlo_data']['sample_paths'],
                    last_analysis['monte_carlo_data']['final_prices'],
                    last_analysis['metrics'].symbol
                )
                
                # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≥—Ä–∞—Ñ–∏–∫
                await context.bot.send_photo(
                    chat_id=query.message.chat_id,
                    photo=InputFile(mc_chart, filename=f"mc_{last_analysis['metrics'].symbol}.png"),
                    caption=f"üìà Monte Carlo —Å–∏–º—É–ª—è—Ü–∏—è –¥–ª—è {last_analysis['metrics'].symbol}"
                )
            
            if 'returns_data' in last_analysis:
                dist_chart = self.graph_generator.generate_distribution_chart(
                    last_analysis['returns_data'],
                    last_analysis['metrics'].symbol
                )
                
                await context.bot.send_photo(
                    chat_id=query.message.chat_id,
                    photo=InputFile(dist_chart, filename=f"dist_{last_analysis['metrics'].symbol}.png"),
                    caption=f"üìä –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–µ–π {last_analysis['metrics'].symbol}"
                )
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç—á–µ—Ç (—Ä–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —á–∞—Å—Ç–∏ –µ—Å–ª–∏ –¥–ª–∏–Ω–Ω—ã–π)
            chunks = [text_report[i:i+4000] for i in range(0, len(text_report), 4000)]
            
            for i, chunk in enumerate(chunks):
                await context.bot.send_message(
                    chat_id=query.message.chat_id,
                    text=f"```\n{chunk}\n```" if i == 0 else f"```\n{chunk}",
                    parse_mode='Markdown'
                )
            
            # –ü—Ä–µ–¥–ª–∞–≥–∞–µ–º —ç–∫—Å–ø–æ—Ä—Ç
            keyboard = [
                [
                    InlineKeyboardButton("üìù TXT", callback_data=f"export_txt_{last_analysis['metrics'].symbol}"),
                    InlineKeyboardButton("üìä CSV", callback_data=f"export_csv_{last_analysis['metrics'].symbol}"),
                    InlineKeyboardButton("üìã JSON", callback_data=f"export_json_{last_analysis['metrics'].symbol}")
                ],
                [InlineKeyboardButton("üîÑ –ù–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑", callback_data="analyze_asset")],
                [InlineKeyboardButton("üè† –ì–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é", callback_data="main_menu")]
            ]
            
            await context.bot.send_message(
                chat_id=query.message.chat_id,
                text="‚úÖ –û—Ç—á–µ—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω!\n\n–í—ã–±–µ—Ä–∏—Ç–µ —Ñ–æ—Ä–º–∞—Ç –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞:",
                reply_markup=InlineKeyboardMarkup(keyboard)
            )
            
        except Exception as e:
            logger.error(f"Error generating full report: {e}")
            await query.edit_message_text(
                text="‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç—á–µ—Ç–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞.",
                parse_mode='Markdown'
            )
    
    async def export_menu(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """–ú–µ–Ω—é —ç–∫—Å–ø–æ—Ä—Ç–∞ –æ—Ç—á–µ—Ç–æ–≤"""
        query = update.callback_query
        await query.answer()
        
        user_id = query.from_user.id
        
        if user_id not in self.user_history or not self.user_history[user_id]:
            text = "‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞. –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ –∞–∫—Ç–∏–≤."
        else:
            last_analysis = self.user_history[user_id][-1]
            symbol = last_analysis['metrics'].symbol
            
            text = f"üì§ *–≠–∫—Å–ø–æ—Ä—Ç –æ—Ç—á–µ—Ç–∞ –¥–ª—è {symbol}*\n\n–í—ã–±–µ—Ä–∏—Ç–µ —Ñ–æ—Ä–º–∞—Ç:"
        
        keyboard = [
            [
                InlineKeyboardButton("üìù TXT", callback_data=f"export_txt_{symbol if 'symbol' in locals() else ''}"),
                InlineKeyboardButton("üìä CSV", callback_data=f"export_csv_{symbol if 'symbol' in locals() else ''}"),
                InlineKeyboardButton("üìã JSON", callback_data=f"export_json_{symbol if 'symbol' in locals() else ''}")
            ],
            [InlineKeyboardButton("üìà PDF (—Å–∫–æ—Ä–æ)", callback_data="coming_soon")],
            [InlineKeyboardButton("üìä –ü–æ–ª–Ω—ã–π –æ—Ç—á–µ—Ç", callback_data="full_report")],
            [InlineKeyboardButton("üè† –ì–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é", callback_data="main_menu")]
        ]
        
        await query.edit_message_text(
            text=text,
            parse_mode='Markdown',
            reply_markup=InlineKeyboardMarkup(keyboard)
        )
    
    async def handle_export(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞ –æ—Ç—á–µ—Ç–æ–≤"""
        query = update.callback_query
        await query.answer()
        
        data = query.data
        user_id = query.from_user.id
        
        if user_id not in self.user_history or not self.user_history[user_id]:
            await query.answer("‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞", show_alert=True)
            return
        
        last_analysis = self.user_history[user_id][-1]
        metrics = last_analysis['metrics']
        symbol = metrics.symbol
        
        await query.edit_message_text(
            text=f"üîÑ –ì–µ–Ω–µ—Ä–∏—Ä—É—é –æ—Ç—á–µ—Ç –¥–ª—è {symbol}...",
            parse_mode='Markdown'
        )
        
        try:
            if data.startswith("export_txt"):
                # TXT —ç–∫—Å–ø–æ—Ä—Ç
                report = self.report_generator.generate_text_report(metrics)
                bio = io.BytesIO(report.encode('utf-8'))
                bio.seek(0)
                
                await context.bot.send_document(
                    chat_id=query.message.chat_id,
                    document=InputFile(bio, filename=f"report_{symbol}_{datetime.now().strftime('%Y%m%d')}.txt"),
                    caption=f"üìù –¢–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç—á–µ—Ç: {symbol}"
                )
                
            elif data.startswith("export_csv"):
                # CSV —ç–∫—Å–ø–æ—Ä—Ç
                report = self.report_generator.generate_csv_report(metrics)
                bio = io.BytesIO(report.encode('utf-8'))
                bio.seek(0)
                
                await context.bot.send_document(
                    chat_id=query.message.chat_id,
                    document=InputFile(bio, filename=f"report_{symbol}_{datetime.now().strftime('%Y%m%d')}.csv"),
                    caption=f"üìä CSV –æ—Ç—á–µ—Ç: {symbol}"
                )
                
            elif data.startswith("export_json"):
                # JSON —ç–∫—Å–ø–æ—Ä—Ç
                report = self.report_generator.generate_json_report(metrics)
                bio = io.BytesIO(report.encode('utf-8'))
                bio.seek(0)
                
                await context.bot.send_document(
                    chat_id=query.message.chat_id,
                    document=InputFile(bio, filename=f"report_{symbol}_{datetime.now().strftime('%Y%m%d')}.json"),
                    caption=f"üìã JSON –æ—Ç—á–µ—Ç: {symbol}"
                )
            
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º—Å—è –≤ –º–µ–Ω—é
            keyboard = [
                [InlineKeyboardButton("üì§ –ï—â–µ –æ—Ç—á–µ—Ç—ã", callback_data="export_menu")],
                [InlineKeyboardButton("üè† –ì–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é", callback_data="main_menu")]
            ]
            
            await context.bot.send_message(
                chat_id=query.message.chat_id,
                text="‚úÖ –û—Ç—á–µ—Ç —É—Å–ø–µ—à–Ω–æ —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω!",
                reply_markup=InlineKeyboardMarkup(keyboard)
            )
            
        except Exception as e:
            logger.error(f"Error exporting report: {e}")
            await query.edit_message_text(
                text="‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —ç–∫—Å–ø–æ—Ä—Ç–µ –æ—Ç—á–µ—Ç–∞.",
                parse_mode='Markdown'
            )
    
    async def portfolio_correlation_analysis(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """–ê–Ω–∞–ª–∏–∑ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π –≤ –ø–æ—Ä—Ç—Ñ–µ–ª–µ"""
        query = update.callback_query
        await query.answer()
        
        user_id = query.from_user.id
        
        if user_id not in user_portfolios or not user_portfolios[user_id]:
            await query.edit_message_text(
                text="‚ùå –£ –≤–∞—Å –Ω–µ—Ç –ø–æ—Ä—Ç—Ñ–µ–ª—è –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞.",
                parse_mode='Markdown'
            )
            return
        
        await query.edit_message_text(
            text="üîÑ –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ –≤ –ø–æ—Ä—Ç—Ñ–µ–ª–µ...",
            parse_mode='Markdown'
        )
        
        try:
            portfolio = user_portfolios[user_id]
            assets = list(portfolio.keys())
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å–∏–º—É–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ –¥–ª—è MVP
            import numpy as np
            
            num_assets = len(assets)
            returns_matrix = np.random.randn(100, num_assets)  # –°–ª—É—á–∞–π–Ω—ã–µ –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏
            
            # –°–æ–∑–¥–∞–µ–º —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—É—é –º–∞—Ç—Ä–∏—Ü—É –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π
            base_corr = 0.3  # –ë–∞–∑–æ–≤–∞—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è
            corr_matrix = np.eye(num_assets) + base_corr
            np.fill_diagonal(corr_matrix, 1)
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ —Å –∑–∞–¥–∞–Ω–Ω–æ–π –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–µ–π
            L = np.linalg.cholesky(corr_matrix)
            correlated_returns = np.dot(returns_matrix, L.T)
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –≥—Ä–∞—Ñ–∏–∫
            chart = self.graph_generator.generate_correlation_matrix(assets, correlated_returns)
            
            # –†–∞—Å—á–µ—Ç –¥–∏–≤–µ—Ä—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
            weights = [portfolio[asset]['weight'] for asset in assets]
            div_metrics = self.analytics_engine.calculate_portfolio_diversification(weights, corr_matrix)
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≥—Ä–∞—Ñ–∏–∫
            await context.bot.send_photo(
                chat_id=query.message.chat_id,
                photo=InputFile(chart, filename="correlation_matrix.png"),
                caption=(
                    f"üìä *–ú–∞—Ç—Ä–∏—Ü–∞ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π –ø–æ—Ä—Ç—Ñ–µ–ª—è*\n\n"
                    f"‚Ä¢ –ê–∫—Ç–∏–≤–æ–≤: {num_assets}\n"
                    f"‚Ä¢ –°—Ä–µ–¥–Ω—è—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è: {div_metrics['avg_correlation']:.2f}\n"
                    f"‚Ä¢ –û—Ü–µ–Ω–∫–∞ –¥–∏–≤–µ—Ä—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏: {div_metrics['diversification_score']:.0f}/100\n"
                    f"‚Ä¢ –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã—Ö –∞–∫—Ç–∏–≤–æ–≤: {div_metrics['effective_assets']:.1f}"
                ),
                parse_mode='Markdown'
            )
            
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
            text = "üí° *–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –¥–∏–≤–µ—Ä—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏:*\n\n"
            
            if div_metrics['avg_correlation'] > 0.7:
                text += "‚Ä¢ –í—ã—Å–æ–∫–∞—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è - –¥–æ–±–∞–≤—å—Ç–µ –∞–∫—Ç–∏–≤—ã –∏–∑ –¥—Ä—É–≥–∏—Ö –∫–ª–∞—Å—Å–æ–≤\n"
            if div_metrics['diversification_score'] < 60:
                text += "‚Ä¢ –ù–∏–∑–∫–∞—è –¥–∏–≤–µ—Ä—Å–∏—Ñ–∏–∫–∞—Ü–∏—è - —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–∏—Ç–µ –∫–∞–ø–∏—Ç–∞–ª\n"
            if div_metrics['concentration_risk'] > 0.3:
                text += "‚Ä¢ –í—ã—Å–æ–∫–∞—è –∫–æ–Ω—Ü–µ–Ω—Ç—Ä–∞—Ü–∏—è - —É–º–µ–Ω—å—à–∏—Ç–µ –ø–æ–∑–∏—Ü–∏–∏ –≤ –∫—Ä—É–ø–Ω–µ–π—à–∏—Ö –∞–∫—Ç–∏–≤–∞—Ö\n"
            
            if "–í—ã—Å–æ–∫–∞—è" not in text and "–ù–∏–∑–∫–∞—è" not in text and "–í—ã—Å–æ–∫–∞—è" not in text:
                text += "‚Ä¢ –ü–æ—Ä—Ç—Ñ–µ–ª—å —Ö–æ—Ä–æ—à–æ –¥–∏–≤–µ—Ä—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω\n"
            
            keyboard = [
                [InlineKeyboardButton("üìà Risk Radar", callback_data="risk_radar")],
                [InlineKeyboardButton("üí∞ –ü–æ—Ä—Ç—Ñ–µ–ª—å", callback_data="manage_portfolio")],
                [InlineKeyboardButton("üè† –ì–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é", callback_data="main_menu")]
            ]
            
            await context.bot.send_message(
                chat_id=query.message.chat_id,
                text=text,
                parse_mode='Markdown',
                reply_markup=InlineKeyboardMarkup(keyboard)
            )
            
        except Exception as e:
            logger.error(f"Error in correlation analysis: {e}")
            await query.edit_message_text(
                text="‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π.",
                parse_mode='Markdown'
            )
    
    async def risk_radar_analysis(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """–†–∞–¥–∞—Ä-–¥–∏–∞–≥—Ä–∞–º–º–∞ —Ä–∏—Å–∫–æ–≤ –ø–æ—Ä—Ç—Ñ–µ–ª—è"""
        query = update.callback_query
        await query.answer()
        
        user_id = query.from_user.id
        
        if user_id not in user_portfolios or not user_portfolios[user_id]:
            await query.edit_message_text(
                text="‚ùå –£ –≤–∞—Å –Ω–µ—Ç –ø–æ—Ä—Ç—Ñ–µ–ª—è –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞.",
                parse_mode='Markdown'
            )
            return
        
        await query.edit_message_text(
            text="üîÑ –ì–µ–Ω–µ—Ä–∏—Ä—É—é —Ä–∞–¥–∞—Ä-–¥–∏–∞–≥—Ä–∞–º–º—É —Ä–∏—Å–∫–æ–≤...",
            parse_mode='Markdown'
        )
        
        try:
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –º–µ—Ç—Ä–∏–∫–∏ —Ä–∏—Å–∫–∞ (–¥–ª—è MVP - —Å–∏–º—É–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ)
            risk_metrics = {
                'volatility_score': 65,
                'drawdown_risk': 45,
                'concentration_risk': 70,
                'correlation_risk': 55,
                'liquidity_risk': 30,
                'market_risk': 60
            }
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –≥—Ä–∞—Ñ–∏–∫
            chart = self.graph_generator.generate_risk_radar_chart(risk_metrics)
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≥—Ä–∞—Ñ–∏–∫
            await context.bot.send_photo(
                chat_id=query.message.chat_id,
                photo=InputFile(chart, filename="risk_radar.png"),
                caption=(
                    "üéØ *–ü—Ä–æ—Ñ–∏–ª—å —Ä–∏—Å–∫–∞ –ø–æ—Ä—Ç—Ñ–µ–ª—è*\n\n"
                    "‚Ä¢ üìä –í–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å: –£–º–µ—Ä–µ–Ω–Ω–∞—è\n"
                    "‚Ä¢ üìâ –†–∏—Å–∫ —Å–Ω–∏–∂–µ–Ω–∏—è: –ù–∏–∑–∫–∏–π\n"
                    "‚Ä¢ üéØ –ö–æ–Ω—Ü–µ–Ω—Ç—Ä–∞—Ü–∏—è: –í—ã—Å–æ–∫–∞—è\n"
                    "‚Ä¢ üîó –ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è: –£–º–µ—Ä–µ–Ω–Ω–∞—è\n"
                    "‚Ä¢ üíß –õ–∏–∫–≤–∏–¥–Ω–æ—Å—Ç—å: –•–æ—Ä–æ—à–∞—è\n"
                    "‚Ä¢ üìà –†—ã–Ω–æ—á–Ω—ã–π —Ä–∏—Å–∫: –£–º–µ—Ä–µ–Ω–Ω—ã–π"
                ),
                parse_mode='Markdown'
            )
            
            keyboard = [
                [InlineKeyboardButton("üìä –ö–æ—Ä—Ä–µ–ª—è—Ü–∏–∏", callback_data="portfolio_correlation")],
                [InlineKeyboardButton("‚ö†Ô∏è –°—Ç—Ä–µ—Å—Å-—Ç–µ—Å—Ç", callback_data="stress_test")],
                [InlineKeyboardButton("üè† –ì–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é", callback_data="main_menu")]
            ]
            
            await context.bot.send_message(
                chat_id=query.message.chat_id,
                text="üí° *–ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è:*\n–ß–µ–º –±–ª–∏–∂–µ –∫ –∫—Ä–∞—é - —Ç–µ–º –≤—ã—à–µ —Ä–∏—Å–∫ –ø–æ —ç—Ç–æ–º—É –ø–∞—Ä–∞–º–µ—Ç—Ä—É.",
                reply_markup=InlineKeyboardMarkup(keyboard)
            )
            
        except Exception as e:
            logger.error(f"Error generating risk radar: {e}")
            await query.edit_message_text(
                text="‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ä–∞–¥–∞—Ä-–¥–∏–∞–≥—Ä–∞–º–º—ã.",
                parse_mode='Markdown'
            )

# ==================== ENHANCED WEB SERVER ====================
class EnhancedWebhookServer(WebhookServer):
    """–†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –≤–µ–±-—Å–µ—Ä–≤–µ—Ä —Å –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–æ–º"""
    
    async def enhanced_health_check(self, request):
        """–†–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è"""
        import psutil
        
        health_data = {
            "status": "healthy",
            "timestamp": datetime.now().isoformat(),
            "service": "risk-calculator-pro",
            "version": "MVP 3.0",
            "resources": {}
        }
        
        try:
            # –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ —Ä–µ—Å—É—Ä—Å–æ–≤
            process = psutil.Process()
            memory_info = process.memory_info()
            
            health_data["resources"] = {
                "memory_mb": round(memory_info.rss / 1024 / 1024, 1),
                "memory_percent": round(process.memory_percent(), 1),
                "cpu_percent": round(process.cpu_percent(), 1),
                "threads": process.num_threads(),
                "connections": len(process.connections()) if hasattr(process, 'connections') else 0
            }
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
            components = {}
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≥—Ä–∞—Ñ–∏—á–µ—Å–∫–æ–≥–æ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞
            try:
                test_chart = AdvancedGraphGenerator().generate_monte_carlo_chart(
                    100, [[100, 110, 105]], [105], "TEST"
                )
                components["graph_generator"] = "operational"
            except Exception as e:
                components["graph_generator"] = f"error: {str(e)}"
                health_data["status"] = "degraded"
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–æ–≥–æ –¥–≤–∏–∂–∫–∞
            try:
                test_metrics = EnhancedAnalyticsEngine().calculate_technical_indicators([100, 105, 103, 108])
                components["analytics_engine"] = "operational"
            except Exception as e:
                components["analytics_engine"] = f"error: {str(e)}"
                health_data["status"] = "degraded"
            
            health_data["components"] = components
            
            # Memory guard check
            if health_data["resources"]["memory_mb"] > 400:
                health_data["status"] = "warning"
                health_data["message"] = "High memory usage detected"
                MemoryGuardian.check_and_clear()
            
        except Exception as e:
            health_data["status"] = "error"
            health_data["error"] = str(e)
        
        return web.json_response(health_data)
    
    async def start(self):
        """–ó–∞–ø—É—Å–∫ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–≥–æ —Å–µ—Ä–≤–µ—Ä–∞"""
        app = web.Application()
        
        # Add enhanced routes
        app.router.add_post(WEBHOOK_PATH, self.handle_webhook)
        app.router.add_get('/health', self.enhanced_health_check)
        app.router.add_get('/health/simple', self.health_check)
        app.router.add_get('/metrics', self.metrics_endpoint)
        app.router.add_get('/', self.health_check)
        
        # Start server
        self.runner = web.AppRunner(app)
        await self.runner.setup()
        
        self.site = web.TCPSite(self.runner, '0.0.0.0', self.port)
        await self.site.start()
        
        logger.info(f"Enhanced webhook server started on port {self.port}")
    
    async def metrics_endpoint(self, request):
        """Endpoint –¥–ª—è –º–µ—Ç—Ä–∏–∫ Prometheus"""
        import psutil
        
        metrics = []
        process = psutil.Process()
        
        # Memory metrics
        memory = process.memory_info()
        metrics.append(f"memory_rss_bytes {memory.rss}")
        metrics.append(f"memory_vms_bytes {memory.vms}")
        metrics.append(f"memory_percent {process.memory_percent()}")
        
        # CPU metrics
        metrics.append(f"cpu_percent {process.cpu_percent()}")
        
        # Thread count
        metrics.append(f"threads_total {process.num_threads()}")
        
        # User sessions
        metrics.append(f"user_sessions_total {len(user_sessions)}")
        metrics.append(f"user_portfolios_total {len(user_portfolios)}")
        
        # Graph generator stats
        if hasattr(graph_generator, 'figures_created'):
            metrics.append(f"figures_created_total {graph_generator.figures_created}")
        
        response_text = "\n".join([f"risk_calculator_{m}" for m in metrics])
        return web.Response(text=response_text, content_type='text/plain')

# ==================== MAIN APPLICATION ====================
async def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è"""
    logger.info("üöÄ –ó–∞–ø—É—Å–∫ PRO Risk Calculator MVP Phase 3 (Complete)")
    logger.info("‚úÖ –í—Å–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –∑–∞–≥—Ä—É–∂–µ–Ω—ã")
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–≥–æ –±–æ—Ç–∞
    bot = EnhancedTelegramBot(TOKEN)
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
    application = Application.builder().token(TOKEN).build()
    
    # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤ –∫–æ–º–∞–Ω–¥ –∏–∑ Phase 2
    application.add_handler(CommandHandler("start", bot.start))
    application.add_handler(CommandHandler("help", bot.help_command))
    application.add_handler(CommandHandler("portfolio", bot.manage_portfolio))
    application.add_handler(CommandHandler("stress", bot.stress_test))
    application.add_handler(CommandHandler("alerts", bot.alerts_menu))
    application.add_handler(CommandHandler("export", bot.export_menu))
    application.add_handler(CommandHandler("advanced", bot.advanced_analysis))
    
    # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤ Phase 3
    application.add_handler(CallbackQueryHandler(bot.advanced_analysis, pattern="^advanced_analysis$"))
    application.add_handler(CallbackQueryHandler(bot.generate_full_report, pattern="^full_report$"))
    application.add_handler(CallbackQueryHandler(bot.export_menu, pattern="^export_menu$"))
    application.add_handler(CallbackQueryHandler(bot.handle_export, pattern="^export_"))
    application.add_handler(CallbackQueryHandler(bot.portfolio_correlation_analysis, pattern="^portfolio_correlation$"))
    application.add_handler(CallbackQueryHandler(bot.risk_radar_analysis, pattern="^risk_radar$"))
    
    # –û—Å—Ç–∞–ª—å–Ω—ã–µ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ –∏–∑ Phase 2
    application.add_handler(CallbackQueryHandler(bot.callback_handler))
    
    # Fallback –æ–±—Ä–∞–±–æ—Ç—á–∏–∫
    application.add_handler(MessageHandler(
        filters.TEXT & ~filters.COMMAND,
        lambda u, c: u.message.reply_text(
            "–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ /start –¥–ª—è –Ω–∞—á–∞–ª–∞ —Ä–∞–±–æ—Ç—ã –∏–ª–∏ –≤—ã–±–µ—Ä–∏—Ç–µ –∫–æ–º–∞–Ω–¥—É –∏–∑ –º–µ–Ω—é."
        )
    ))
    
    # –ó–∞–ø—É—Å–∫ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ä–µ–∂–∏–º–∞
    if WEBHOOK_URL and WEBHOOK_URL.strip():
        logger.info("üåê –ó–∞–ø—É—Å–∫ –≤ —Ä–µ–∂–∏–º–µ Webhook")
        
        # –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –≤–µ–±—Ö—É–∫–∞
        webhook_url = f"{WEBHOOK_URL}{WEBHOOK_PATH}"
        await application.bot.set_webhook(
            url=webhook_url,
            allowed_updates=Update.ALL_TYPES
        )
        logger.info(f"Webhook —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω: {webhook_url}")
        
        # –ó–∞–ø—É—Å–∫ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–≥–æ —Å–µ—Ä–≤–µ—Ä–∞
        server = EnhancedWebhookServer(application, PORT)
        await server.start()
        
        # –û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª —Å –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–æ–º
        try:
            while True:
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–∞–º—è—Ç–∏ –∫–∞–∂–¥—ã–µ 5 –º–∏–Ω—É—Ç
                MemoryGuardian.check_and_clear()
                
                # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∫–∞–∂–¥—ã–µ 30 –º–∏–Ω—É—Ç
                if datetime.now().minute % 30 == 0:
                    logger.info(f"–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞: –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π: {len(user_sessions)}, "
                              f"–ü–æ—Ä—Ç—Ñ–µ–ª–µ–π: {len(user_portfolios)}, "
                              f"–ì—Ä–∞—Ñ–∏–∫–æ–≤ —Å–æ–∑–¥–∞–Ω–æ: {bot.graph_generator.figures_created}")
                
                await asyncio.sleep(300)  # 5 –º–∏–Ω—É—Ç
                
        except KeyboardInterrupt:
            logger.info("‚èπ –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø–æ –∫–æ–º–∞–Ω–¥–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è")
            await server.stop()
            
    else:
        logger.info("üîÑ –ó–∞–ø—É—Å–∫ –≤ —Ä–µ–∂–∏–º–µ Polling")
        
        # –ó–∞–ø—É—Å–∫ polling
        await application.initialize()
        await application.start()
        await application.updater.start_polling(
            poll_interval=1.0,
            timeout=30,
            drop_pending_updates=True
        )
        
        logger.info("‚úÖ –ë–æ—Ç –∑–∞–ø—É—â–µ–Ω –≤ —Ä–µ–∂–∏–º–µ polling")
        
        try:
            while True:
                await asyncio.sleep(1)
        except KeyboardInterrupt:
            logger.info("‚èπ –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø–æ –∫–æ–º–∞–Ω–¥–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è")
            await application.stop()

# ==================== GLOBALS AND INITIALIZATION ====================
# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ —ç–∫–∑–µ–º–ø–ª—è—Ä—ã
graph_generator = AdvancedGraphGenerator()
report_generator = ReportGenerator()
analytics_engine = EnhancedAnalyticsEngine()

# –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ
user_sessions = {}
user_portfolios = {}
user_alerts = {}

# –î–µ–∫–æ—Ä–∞—Ç–æ—Ä –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ (–æ–ø—Ä–µ–¥–µ–ª–µ–Ω —Ä–∞–Ω–µ–µ)
def monitor_performance(func):
    @functools.wraps(func)
    async def async_wrapper(*args, **kwargs):
        start_time = time.time()
        try:
            result = await func(*args, **kwargs)
            elapsed = time.time() - start_time
            if elapsed > 1.0:
                logger.warning(f"Slow operation: {func.__name__} took {elapsed:.2f}s")
            return result
        except Exception as e:
            elapsed = time.time() - start_time
            logger.error(f"Error in {func.__name__} after {elapsed:.2f}s: {e}")
            raise
    return async_wrapper

# ==================== ENTRY POINT ====================
if __name__ == "__main__":
    try:
        asyncio.run(main())
    except Exception as e:
        logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
